
# HDT 8: Redes Neuronales Artificiales (RNA)

{r message=FALSE, warning=FALSE}
#Librerias necesarias
library(caret)
library(nnet)
library(neural)
library(dummy)
library(neuralnet)


#Conjunto de datos a utilizar
data<-read.csv('train.csv')



#Quitar nulos
data[is.na(data)] <- 0
#Calculo de percentiles
percentil <- quantile(data$SalePrice)
#Percentiles
estado<-c('Estado')
data$Estado<-estado
#Economica=0
#Intermedia=1
#Cara=2
data <- within(data, Estado[SalePrice<=129975] <- 'Economica')
data$Estado[(data$SalePrice>129975 & data$SalePrice<=163000)] <- 'Intermedia'
data$Estado[data$SalePrice>163000] <- 'Cara'


#Cambio de tipo de columnas

data$SalePrice<-as.numeric(data$SalePrice)
data$GrLivArea<-as.numeric(data$GrLivArea)
data$GarageCars<-as.numeric(data$GarageCars)
data$YearBuilt<-as.numeric(data$YearBuilt)
data$GarageArea<-as.numeric(data$GarageArea)
data$X1stFlrSF<-as.numeric(data$X1stFlrSF)

data$Estado<-as.factor(data$Estado)

porcentaje<-0.7
set.seed(123)
datos<-data.frame(data$SalePrice,data$GrLivArea,data$GarageCars,data$YearBuilt,data$GarageArea,data$X1stFlrSF,data$Estado)

corte <- sample(nrow(datos),nrow(datos)*porcentaje)
train<-datos[corte,]
test<-datos[-corte,]

#-------------------------------------------------
# Red Neuronal con nnet
#-------------------------------------------------

modelo.nn2 <- nnet(data.Estado~.,data = datos,subset = corte, size=2, rang=0.1,
                   decay=5e-4, maxit=200) 
prediccion2 <- as.data.frame(predict(modelo.nn2, newdata = test[,1:6]))
columnaMasAlta<-apply(prediccion2, 1, function(x) colnames(prediccion2)[which.max(x)])
test$prediccion2<-columnaMasAlta #Se le añade al grupo de prueba el valor de la predicción

modelo1<-confusionMatrix(as.factor(test$prediccion2),test$data.Estado)


#-------------------------------------------------
# Red Neuronal con caret
#-------------------------------------------------

modeloCaret <- train(data.Estado~., data=train, method="nnet", trace=F)
test$prediccionCaret<-predict(modeloCaret, newdata = test[,1:6])
modelo2<-confusionMatrix(test$prediccionCaret,test$data.Estado)

### Modelos de clasificación usando redes neuronales.
#### Usando nnet

{r}
modelo1


En el primer modelo se observa que la precisión y otras estadísticas tienen valores ni muy bajos ni tan altos. La precisión fue de 0.5125 y se debe a que las variables seleccionadas para realizar la clasificación no fueron las mejores. Además, este modelo en sí tiene el riesgo de equivocarse más, ya que en este caso se equivocó con 214 casas al momento de clasificarlas.

#### Usando caret

{r}
modelo2


Ahora con el segundo modelo percibimos mejores resultados, obteniendo una precisión de 0.7585 y por ende, las equivocaciones de este modelo fueron menos, siendo 106 casas mal clasificadas.

Entonces, el segundo modelo fue mejor en cuanto a efectividad y menor número de equivocaciones. Y respecto al tiempo de procesamiento, ambos tomaron tiempos similares al ejecutarse.



### SalePrice como variable de respuesta.

{r message=FALSE, warning=FALSE}
#Librerias necesarias
library(nnet)
library(neuralnet)
library(ggplot2)


#Conjunto de datos a utilizar
data<-read.csv('train.csv')


#Cambio de tipo de columnas

data$SalePrice<-as.numeric(data$SalePrice)
data$GrLivArea<-as.numeric(data$GrLivArea)
data$GarageCars<-as.numeric(data$GarageCars)
data$YearBuilt<-as.numeric(data$YearBuilt)
data$GarageArea<-as.numeric(data$GarageArea)
data$X1stFlrSF<-as.numeric(data$X1stFlrSF)
#Funcion para normalizar los datos
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}



porcentaje<-0.7
set.seed(123)
#Creamos el dataframe para predecir
datos2<-data.frame(data$GrLivArea,data$GarageCars,data$YearBuilt,data$GarageArea,data$X1stFlrSF,data$SalePrice)
#Creamos el dataframe con los datos normalizados
datos <- as.data.frame(lapply(datos2, normalize))


corte <- sample(nrow(datos),nrow(datos)*porcentaje)
train<-datos[corte,]
test<-datos[-corte,]

#-------------------------------------------------
# Red Neuronal con nnet
#-------------------------------------------------
#Prediccion
modelo.nn2 <- nnet(as.numeric(data.SalePrice)~.,data = datos,subset = corte, size=2, rang=0.1,decay=5e-4, maxit=200) 
prediccion1 <- predict(modelo.nn2, newdata = test,na.rm=TRUE)

#Desnormalizar datos
minvec <- sapply(datos2,min)
maxvec <- sapply(datos2,max)
denormalize <- function(x,minval,maxval) {
  x*(maxval-minval) + minval
}
#Desnormalizamos el dataframe
datos<-as.data.frame(Map(denormalize,datos,minvec,maxvec))
#Desnormalizamos la prediccion
prediccion1_r<-(prediccion1)*(max(datos2)-min(datos2))+min(datos2)



{r}
plot(datos$data.SalePrice)


{r}
plot(prediccion1_r)
















### Compare los dos modelos de regresión y determine cuál funcionó mejor para predecir el precio de las casas. 

El modelo que nos funciono mejor fue el primer modelo, el modelo en el cual utilizamos nuestra variable categorica y no la variable SalePrice, por ende podemos concluir con que el mejor modelo para precedir el precio de las casas fue el metodo #1 con el modelo #2. 

### Compare  la  eficiencia  del  mejor  modelo  de  RNA  con  los  resultados  obtenidos  con  los algoritmos  de  las  hojas de  trabajo  anteriores.  ¿Cuál  es  mejor  para  predecir?  ¿Cuál  se demoró más en procesar? 

Nuestro modelo numero #2, fue nuestro mejor modelo, obtuvo un valor de 0.75%, realmente comparado con las hojas de trabajo anteriores no es el mejor modelo, porque es un valor bajo, pero realmente cumple con su funcion, hace de una manera correcta la prediccion, pero el cual puede mejorar posiblemente cambiando las variables categoricas o incluso agregando mas variables. Pero a nivel de demora, realmente todos se toman el mismo tiempo, tiempo que solo varia en cuestion de milisegundos o incluso en el mayor de los casos, un segundo.


### Compare los resultados del mejor modelo de esta hoja para clasificar con los resultados de los algoritmos usados para clasificar de las hojas de trabajo anteriores 


En esta hoja, el mejor resultado que logramos fue con el modelo #2, el que realizamos con la libreria de Caret, obtuvimos un acierto del 0.75%, comparado con las hojas de trabajo anteriores, la verdad es que esta un poco bajo, mas sin embargo no esta fuera de la media que hemos tenido, podemos mencionar la hoja de trabajo con Arboles de decision, en la cual obtuvimos un valor de 0.70, lo cual es bastante semejante, pero comparado con las otra hojas sigue siendo bajo. 

### Compare  los  resultados  del  mejor  modelo  para  predecir  el  precio  de  venta  con  los resultados  de  los  algoritmos  usados  para  el  mismo  propósito  de  las  hojas  de  trabajo anteriores. 


Comparado con las hojas de trabajo anteriores, tuvimos un nivel estandar, hemos tenido resultados que estan en el rango, podriamos decir que solo se hace una variacion por decimales. 

### Ahora que ha usado todos los modelos que hemos visto y aplicados al conjunto de datos llegue a conclusiones sobre cual es o cuales son los mejores modelos para clasificar dadas las  características  del  conjunto  de  datos.  ¿Cuál  o  cuáles  son  los mejores  para  predecir  el precio de las casas? 

Realmente, luego de haber trabajado con todos los modelos, y tomando en cuanta los resultados anteriores, podemos concluir que el mejor modelo, o por lo menos el modelo que mejor nos resulto a nosotros, fue el modelo de Naive Bayes, en ese modelo llegamos a tener un nivel de acierto del 0.93%, lo cual podemos decir que es casi excelente, el otro modelo que nos ha resultado muy eficiente fue el de Random Forest, con el cual llegamos a tener un nivel de acierto de 0.82%. 

Con base en lo anterior, podemos entoncer concluir con que los mejores modelos para precedir el precio de las casas con las condiciones dadas por el conjunto de datos, son: 

1. NAIVE BAYES.

2. RANDOM FOREST.
